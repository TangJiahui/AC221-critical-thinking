{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### By Jiahui Tang, Tiffany Yang, Xin Zeng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "FillNA and descriptively look at quasi columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('APCOMP221Pset1.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>registered</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>completed</th>\n",
       "      <th>ip</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>roles_isInstructor</th>\n",
       "      <th>roles_isStaff</th>\n",
       "      <th>roles_isCCX</th>\n",
       "      <th>roles_isFinance</th>\n",
       "      <th>roles_isLibrary</th>\n",
       "      <th>roles_isSales</th>\n",
       "      <th>forumRoles_isAdmin</th>\n",
       "      <th>forumRoles_isCommunityTA</th>\n",
       "      <th>forumRoles_isModerator</th>\n",
       "      <th>forumRoles_isStudent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1488411</td>\n",
       "      <td>KIRSTEN SUAREZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.108.107.58</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>7013084</td>\n",
       "      <td>CAREY FOSTER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>205.175.107.76</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4083257</td>\n",
       "      <td>CLAUDINE FARMER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.212.146.137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4605571</td>\n",
       "      <td>SHEREE BONNER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>172.221.204.94</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1499820</td>\n",
       "      <td>MITCHELL VALDEZ</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>193.225.200.92</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id  user_id         username  registered  viewed  \\\n",
       "0  HarvardX/PH525.1x/1T2018  1488411   KIRSTEN SUAREZ        True   False   \n",
       "1  HarvardX/PH525.1x/1T2018  7013084     CAREY FOSTER        True    True   \n",
       "2  HarvardX/PH525.1x/1T2018  4083257  CLAUDINE FARMER        True    True   \n",
       "3  HarvardX/PH525.1x/1T2018  4605571    SHEREE BONNER        True    True   \n",
       "4  HarvardX/PH525.1x/1T2018  1499820  MITCHELL VALDEZ        True    True   \n",
       "\n",
       "  explored  certified  completed               ip cc_by_ip  ...  \\\n",
       "0      NaN      False      False    81.108.107.58       GB  ...   \n",
       "1     True      False      False   205.175.107.76       US  ...   \n",
       "2    False      False      False  103.212.146.137      NaN  ...   \n",
       "3    False      False      False   172.221.204.94       US  ...   \n",
       "4     True      False      False   193.225.200.92       HU  ...   \n",
       "\n",
       "  roles_isInstructor roles_isStaff roles_isCCX roles_isFinance  \\\n",
       "0                NaN           NaN         NaN             NaN   \n",
       "1                NaN           NaN         NaN             NaN   \n",
       "2                NaN           NaN         NaN             NaN   \n",
       "3                NaN           NaN         NaN             NaN   \n",
       "4                NaN           NaN         NaN             NaN   \n",
       "\n",
       "  roles_isLibrary roles_isSales forumRoles_isAdmin forumRoles_isCommunityTA  \\\n",
       "0             NaN           NaN                NaN                      NaN   \n",
       "1             NaN           NaN                NaN                      NaN   \n",
       "2             NaN           NaN                NaN                      NaN   \n",
       "3             NaN           NaN                NaN                      NaN   \n",
       "4             NaN           NaN                NaN                      NaN   \n",
       "\n",
       "  forumRoles_isModerator forumRoles_isStudent  \n",
       "0                    NaN                  1.0  \n",
       "1                    NaN                  1.0  \n",
       "2                    NaN                  1.0  \n",
       "3                    NaN                  1.0  \n",
       "4                    NaN                  1.0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_lists = ['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region',\n",
    "              'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', \n",
    "              'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', \n",
    "              'mode', 'email_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1141735 entries, 0 to 1141734\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   course_id        1141735 non-null  object \n",
      " 1   cc_by_ip         957309 non-null   object \n",
      " 2   countryLabel     957540 non-null   object \n",
      " 3   continent        959097 non-null   object \n",
      " 4   city             827422 non-null   object \n",
      " 5   region           789588 non-null   object \n",
      " 6   subdivision      807161 non-null   object \n",
      " 7   postalCode       437268 non-null   object \n",
      " 8   LoE              975782 non-null   object \n",
      " 9   YoB              967016 non-null   float64\n",
      " 10  gender           989616 non-null   object \n",
      " 11  nforum_posts     39360 non-null    float64\n",
      " 12  nforum_votes     39360 non-null    float64\n",
      " 13  nforum_endorsed  39360 non-null    float64\n",
      " 14  nforum_threads   39360 non-null    float64\n",
      " 15  nforum_comments  39360 non-null    float64\n",
      " 16  nforum_pinned    39360 non-null    float64\n",
      " 17  nforum_events    874250 non-null   float64\n",
      " 18  mode             1136664 non-null  object \n",
      " 19  email_domain     1141735 non-null  object \n",
      "dtypes: float64(8), object(12)\n",
      "memory usage: 174.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data[quasi_lists].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To identify which columns we need to remove, we plan to use the groupby function in Python. However, groupby function would ignore NaN values when using variables as groups. To ensure we get correct result, we first decide to replace NaN values as -999, which is a numerical value that has not been seen in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fillna = data.fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Suppression K-Anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression\n",
    "def supression(data, quasi_set, k):\n",
    "    len_remove = 0\n",
    "    lst_remove = []\n",
    "    grouped = data.groupby(by=quasi_set)\n",
    "    for name, group in grouped:\n",
    "        if group.shape[0] < k:\n",
    "            len_remove += group.shape[0]\n",
    "            lst_remove.extend(list(group.index))\n",
    "    return len_remove, lst_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get completion rate for each course\n",
    "def complete_rate(data):\n",
    "    grouped = data.groupby(by=[\"course_id\"])\n",
    "    rate = grouped[[\"completed\"]].sum() / grouped[[\"completed\"]].count()\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141749 records of the original edX dataset remain if we use suppression to make it 3-anonymous\n",
      "                            completed\n",
      "course_id                            \n",
      "HarvardX/1368.1x/2T2016      0.000000\n",
      "HarvardX/1368.2x/2T2016      0.000000\n",
      "HarvardX/1368.4x/2T2016      0.000000\n",
      "HarvardX/1368x/2T2017        0.000000\n",
      "HarvardX/AI12.1x/2013_SOND   0.000000\n",
      "...                               ...\n",
      "Harvardx/HLS2X/4T2017        0.008065\n",
      "Harvardx/HLS2X/T12016        0.004024\n",
      "VJx/VJx/3T2014               0.000000\n",
      "VJx/VJx_2/3T2016             0.000000\n",
      "VJx/VJx_S/3T2015             0.000000\n",
      "\n",
      "[249 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "len_remove, lst_remove = supression(data_fillna, quasi_lists, 3)\n",
    "len_remain = data_fillna.shape[0] - len_remove\n",
    "print(str(len_remain) + \" records of the original edX dataset remain if we use suppression to make it 3-anonymous\")\n",
    "data_drop_3 = data_fillna.drop(lst_remove, axis=0)\n",
    "rate_3 = complete_rate(data_drop_3)\n",
    "print(rate_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120995 records of the original edX dataset remain if we use suppression to make it 4-anonymous\n",
      "                            completed\n",
      "course_id                            \n",
      "HarvardX/1368.1x/2T2016      0.000000\n",
      "HarvardX/1368.4x/2T2016      0.000000\n",
      "HarvardX/1368x/2T2017        0.000000\n",
      "HarvardX/AI12.1x/2013_SOND   0.000000\n",
      "HarvardX/AI12.2x/2013_SOND   0.000000\n",
      "...                               ...\n",
      "Harvardx/HLS2X/4T2017        0.010309\n",
      "Harvardx/HLS2X/T12016        0.002370\n",
      "VJx/VJx/3T2014               0.000000\n",
      "VJx/VJx_2/3T2016             0.000000\n",
      "VJx/VJx_S/3T2015             0.000000\n",
      "\n",
      "[227 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "len_remove, lst_remove = supression(data_fillna, quasi_lists, 4)\n",
    "len_remain = data_fillna.shape[0] - len_remove\n",
    "print(str(len_remain) + \" records of the original edX dataset remain if we use suppression to make it 4-anonymous\")\n",
    "data_drop_4 = data_fillna.drop(lst_remove, axis=0)\n",
    "rate_4 = complete_rate(data_drop_4)\n",
    "print(rate_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108195 records of the original edX dataset remain if we use suppression to make it 5-anonymous\n",
      "                            completed\n",
      "course_id                            \n",
      "HarvardX/1368.1x/2T2016      0.000000\n",
      "HarvardX/1368x/2T2017        0.000000\n",
      "HarvardX/AI12.1x/2013_SOND   0.000000\n",
      "HarvardX/AI12.2x/2013_SOND   0.000000\n",
      "HarvardX/AT1x/2T2014         0.008013\n",
      "...                               ...\n",
      "Harvardx/HLS2X/4T2017        0.012346\n",
      "Harvardx/HLS2X/T12016        0.002959\n",
      "VJx/VJx/3T2014               0.000000\n",
      "VJx/VJx_2/3T2016             0.000000\n",
      "VJx/VJx_S/3T2015             0.000000\n",
      "\n",
      "[215 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "len_remove, lst_remove = supression(data_fillna, quasi_lists, 5)\n",
    "len_remain = data_fillna.shape[0] - len_remove\n",
    "print(str(len_remain) + \" records of the original edX dataset remain if we use suppression to make it 5-anonymous\")\n",
    "data_drop_5 = data_fillna.drop(lst_remove, axis=0)\n",
    "rate_5 = complete_rate(data_drop_5)\n",
    "print(rate_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         completed\n",
      "course_id                         \n",
      "HarvardX/1368.1x/2T2016   0.033439\n",
      "HarvardX/1368.1x/3T2014   0.064228\n",
      "HarvardX/1368.2x/2T2015   0.063197\n",
      "HarvardX/1368.2x/2T2016   0.093750\n",
      "HarvardX/1368.3x/2T2015   0.080645\n",
      "...                            ...\n",
      "Harvardx/HLS2X/T12016     0.088883\n",
      "VJx/VJx/3T2014            0.078947\n",
      "VJx/VJx/3T2015            0.089744\n",
      "VJx/VJx_2/3T2016          0.044908\n",
      "VJx/VJx_S/3T2015          0.029350\n",
      "\n",
      "[280 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# baseline completion rate\n",
    "rate_base = complete_rate(data)\n",
    "print(rate_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039608028785280684\n",
      "0.006129202609986929\n",
      "0.00439485648184335\n",
      "0.003453202330136351\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rate_base.completed))\n",
    "print(np.mean(rate_3.completed))\n",
    "print(np.mean(rate_4.completed))\n",
    "print(np.mean(rate_5.completed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since there are more than 200 courses, the completion rate for each course seem a little hard to compare with each other, we further calculate the average values of those courses. And we found that for the original dataset, the average completion rate for each of the course is 3.96%. For 3-anonymous dataset, the average completion rate for each of the course is 0.6%. For 4-anonymous dataset, the average completion rate for each of the course is 0.4%. For 5-anonymous dataset, the average completion rate for each of the course is 0.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed    0.024648\n",
      "dtype: float64\n",
      "completed    0.001799\n",
      "dtype: float64\n",
      "completed    0.001422\n",
      "dtype: float64\n",
      "completed    0.001202\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data[[\"completed\"]].sum() / data[[\"completed\"]].count())\n",
    "print(data_drop_3[[\"completed\"]].sum() / data_drop_3[[\"completed\"]].count())\n",
    "print(data_drop_4[[\"completed\"]].sum() / data_drop_4[[\"completed\"]].count())\n",
    "print(data_drop_5[[\"completed\"]].sum() / data_drop_5[[\"completed\"]].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Furthermore, we also calculate the overall completion rate for further comparision. And we found that for the original dataset, the overall completion rate for each of the course is 2.36%. For 3-anonymous dataset, the average completion rate for each of the course is 0.18%. For 4-anonymous dataset, the average completion rate for each of the course is 0.14%. For 5-anonymous dataset, the average completion rate for each of the course is 0.12%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Synthetic K-Anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding synthetic records\n",
    "def synthetic_records(data, quasi_set, k):\n",
    "    len_add = 0\n",
    "    grouped = data.groupby(by=quasi_set)\n",
    "    for name, group in grouped:\n",
    "        if group.shape[0] < k:\n",
    "            len_add +=  (k - group.shape[0])\n",
    "    return len_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1924273"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_records(data_fillna, quasi_lists, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows we have to add 1924273 records to the original edX dataset to make it 3-anonymous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_records(data_fillna, quasi_lists, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows we have to add 2905944 records to the original edX dataset to make it 3-anonymous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3890815"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_records(data_fillna, quasi_lists, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows we have to add 3890815 records to the original edX dataset to make it 3-anonymous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Generalization or Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>countryLabel</th>\n",
       "      <th>continent</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>subdivision</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>LoE</th>\n",
       "      <th>YoB</th>\n",
       "      <th>gender</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>nforum_votes</th>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <th>nforum_threads</th>\n",
       "      <th>nforum_comments</th>\n",
       "      <th>nforum_pinned</th>\n",
       "      <th>nforum_events</th>\n",
       "      <th>mode</th>\n",
       "      <th>email_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>GB</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>MDB</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audit</td>\n",
       "      <td>hotmail.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98105</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audit</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audit</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audit</td>\n",
       "      <td>hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>HU</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>BU</td>\n",
       "      <td>Budapest fovaros</td>\n",
       "      <td>-999</td>\n",
       "      <td>b</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>m</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audit</td>\n",
       "      <td>gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id cc_by_ip    countryLabel      continent  \\\n",
       "0  HarvardX/PH525.1x/1T2018       GB  United Kingdom         Europe   \n",
       "1  HarvardX/PH525.1x/1T2018       US   United States       Americas   \n",
       "2  HarvardX/PH525.1x/1T2018     -999            -999           -999   \n",
       "3  HarvardX/PH525.1x/1T2018       US   United States  North America   \n",
       "4  HarvardX/PH525.1x/1T2018       HU         Hungary         Europe   \n",
       "\n",
       "            city region       subdivision postalCode   LoE     YoB gender  \\\n",
       "0  Middlesbrough    MDB     Middlesbrough       -999  -999  -999.0   -999   \n",
       "1        Seattle     WA        Washington      98105  -999  -999.0   -999   \n",
       "2           -999   -999              -999       -999  -999  -999.0   -999   \n",
       "3           -999   -999              -999       -999  -999  -999.0   -999   \n",
       "4       Budapest     BU  Budapest fovaros       -999     b  1986.0      m   \n",
       "\n",
       "   nforum_posts  nforum_votes  nforum_endorsed  nforum_threads  \\\n",
       "0        -999.0        -999.0           -999.0          -999.0   \n",
       "1        -999.0        -999.0           -999.0          -999.0   \n",
       "2        -999.0        -999.0           -999.0          -999.0   \n",
       "3        -999.0        -999.0           -999.0          -999.0   \n",
       "4        -999.0        -999.0           -999.0          -999.0   \n",
       "\n",
       "   nforum_comments  nforum_pinned  nforum_events   mode   email_domain  \n",
       "0           -999.0         -999.0            0.0  audit  hotmail.co.uk  \n",
       "1           -999.0         -999.0            0.0  audit      gmail.com  \n",
       "2           -999.0         -999.0            0.0  audit      gmail.com  \n",
       "3           -999.0         -999.0            0.0  audit    hotmail.com  \n",
       "4           -999.0         -999.0            0.0  audit      gmail.com  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_df = data_fillna[quasi_lists]\n",
    "quasi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YoB</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>nforum_votes</th>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <th>nforum_threads</th>\n",
       "      <th>nforum_comments</th>\n",
       "      <th>nforum_pinned</th>\n",
       "      <th>nforum_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "      <td>1.141735e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.527779e+03</td>\n",
       "      <td>-9.643190e+02</td>\n",
       "      <td>-9.644928e+02</td>\n",
       "      <td>-9.645596e+02</td>\n",
       "      <td>-9.644883e+02</td>\n",
       "      <td>-9.643913e+02</td>\n",
       "      <td>-9.645603e+02</td>\n",
       "      <td>-2.316902e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.074101e+03</td>\n",
       "      <td>1.835682e+02</td>\n",
       "      <td>1.826540e+02</td>\n",
       "      <td>1.822660e+02</td>\n",
       "      <td>1.826455e+02</td>\n",
       "      <td>1.831812e+02</td>\n",
       "      <td>1.822620e+02</td>\n",
       "      <td>4.275244e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.969000e+03</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.985000e+03</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.992000e+03</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>-9.990000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.116000e+03</td>\n",
       "      <td>1.091000e+03</td>\n",
       "      <td>2.507000e+03</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>1.420000e+02</td>\n",
       "      <td>1.024000e+03</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>1.782900e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                YoB  nforum_posts  nforum_votes  nforum_endorsed  \\\n",
       "count  1.141735e+06  1.141735e+06  1.141735e+06     1.141735e+06   \n",
       "mean   1.527779e+03 -9.643190e+02 -9.644928e+02    -9.645596e+02   \n",
       "std    1.074101e+03  1.835682e+02  1.826540e+02     1.822660e+02   \n",
       "min   -9.990000e+02 -9.990000e+02 -9.990000e+02    -9.990000e+02   \n",
       "25%    1.969000e+03 -9.990000e+02 -9.990000e+02    -9.990000e+02   \n",
       "50%    1.985000e+03 -9.990000e+02 -9.990000e+02    -9.990000e+02   \n",
       "75%    1.992000e+03 -9.990000e+02 -9.990000e+02    -9.990000e+02   \n",
       "max    3.116000e+03  1.091000e+03  2.507000e+03     7.800000e+01   \n",
       "\n",
       "       nforum_threads  nforum_comments  nforum_pinned  nforum_events  \n",
       "count    1.141735e+06     1.141735e+06   1.141735e+06   1.141735e+06  \n",
       "mean    -9.644883e+02    -9.643913e+02  -9.645603e+02  -2.316902e+02  \n",
       "std      1.826455e+02     1.831812e+02   1.822620e+02   4.275244e+02  \n",
       "min     -9.990000e+02    -9.990000e+02  -9.990000e+02  -9.990000e+02  \n",
       "25%     -9.990000e+02    -9.990000e+02  -9.990000e+02   0.000000e+00  \n",
       "50%     -9.990000e+02    -9.990000e+02  -9.990000e+02   0.000000e+00  \n",
       "75%     -9.990000e+02    -9.990000e+02  -9.990000e+02   0.000000e+00  \n",
       "max      1.420000e+02     1.024000e+03   7.700000e+01   1.782900e+04  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quasi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1141735 entries, 0 to 1141734\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   course_id        1141735 non-null  object \n",
      " 1   cc_by_ip         1141735 non-null  object \n",
      " 2   countryLabel     1141735 non-null  object \n",
      " 3   continent        1141735 non-null  object \n",
      " 4   city             1141735 non-null  object \n",
      " 5   region           1141735 non-null  object \n",
      " 6   subdivision      1141735 non-null  object \n",
      " 7   postalCode       1141735 non-null  object \n",
      " 8   LoE              1141735 non-null  object \n",
      " 9   YoB              1141735 non-null  float64\n",
      " 10  gender           1141735 non-null  object \n",
      " 11  nforum_posts     1141735 non-null  float64\n",
      " 12  nforum_votes     1141735 non-null  float64\n",
      " 13  nforum_endorsed  1141735 non-null  float64\n",
      " 14  nforum_threads   1141735 non-null  float64\n",
      " 15  nforum_comments  1141735 non-null  float64\n",
      " 16  nforum_pinned    1141735 non-null  float64\n",
      " 17  nforum_events    1141735 non-null  float64\n",
      " 18  mode             1141735 non-null  object \n",
      " 19  email_domain     1141735 non-null  object \n",
      "dtypes: float64(8), object(12)\n",
      "memory usage: 174.2+ MB\n"
     ]
    }
   ],
   "source": [
    "quasi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_fillna.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region',\n",
    "                  'subdivision', 'postalCode', 'LoE', 'gender', 'mode', 'email_domain']\n",
    "\n",
    "numerical = ['YoB','nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments',\n",
    "            'nforum_pinned', 'nforum_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in categorical:\n",
    "    df[name] = df[name].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take a look at spans (max-min for numerical columns, number of different values for categorical columns) of all columns for a partition of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spans (max-min for numerical columns, number of different values for categorical columns) \n",
    "## of all columns for a partition of a dataframe.\n",
    "\n",
    "def get_spans(df, partition, scale=None):\n",
    "    spans = {}\n",
    "    for column in df.columns:\n",
    "        if column in categorical:\n",
    "            span = len(df[column][partition].unique())\n",
    "        elif column in numerical:\n",
    "            span = df[column][partition].max()-df[column][partition].min()\n",
    "        else:\n",
    "            continue\n",
    "        if scale is not None:\n",
    "            span = span/scale[column]\n",
    "        spans[column] = span\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course_id': 280, 'cc_by_ip': 226, 'countryLabel': 244, 'continent': 9, 'city': 26138, 'region': 1084, 'subdivision': 2508, 'postalCode': 33174, 'LoE': 12, 'YoB': 4115.0, 'gender': 4, 'nforum_posts': 2090.0, 'nforum_votes': 3506.0, 'nforum_endorsed': 1077.0, 'nforum_threads': 1141.0, 'nforum_comments': 2023.0, 'nforum_pinned': 1076.0, 'nforum_events': 18828.0, 'mode': 4, 'email_domain': 45430}\n"
     ]
    }
   ],
   "source": [
    "full_spans = get_spans(df, df.index)\n",
    "print(full_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take a look at all categorical variables, and check to see whether we should generalize or delete them, or leave it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HarvardX/CS50x3/2015                        126249\n",
      "HarvardX/CS50/X                             124119\n",
      "HarvardX/CS50x/2014_T1                       70600\n",
      "HarvardX/GSD1x/1T2017                        31917\n",
      "HarvardX/MCB80.1x/2013_SOND                  19616\n",
      "                                             ...  \n",
      "HarvardX/HLS1xC/Copyright                       27\n",
      "HarvardX/MUS24.4x/2T2018                        27\n",
      "HarvardX/HLS1xA/Copyright                       26\n",
      "HarvardX/BUS5.1x_Application_Only/3T2015        18\n",
      "HarvardX/HLS1x/2013_Spring                       4\n",
      "Name: course_id, Length: 280, dtype: int64\n",
      "number of values with <5 counts is 1\n",
      "=================================\n",
      "US      308402\n",
      "-999    184426\n",
      "IN       77301\n",
      "GB       40781\n",
      "BR       38065\n",
      "         ...  \n",
      "PW           3\n",
      "ST           2\n",
      "AQ           1\n",
      "FK           1\n",
      "SM           1\n",
      "Name: cc_by_ip, Length: 226, dtype: int64\n",
      "number of values with <5 counts is 11\n",
      "=================================\n",
      "United States                  308402\n",
      "-999                           184195\n",
      "India                           77301\n",
      "United Kingdom                  40781\n",
      "Brazil                          38065\n",
      "                                ...  \n",
      "São Tomé and Príncipe               2\n",
      "Antarctica                          1\n",
      "Sint Maarten (Dutch part)           1\n",
      "Falkland Islands (Malvinas)         1\n",
      "San Marino                          1\n",
      "Name: countryLabel, Length: 244, dtype: int64\n",
      "number of values with <5 counts is 16\n",
      "=================================\n",
      "Americas         408928\n",
      "Asia             230240\n",
      "Europe           206290\n",
      "-999             182638\n",
      "Africa            47113\n",
      "North America     31410\n",
      "Oceania           24916\n",
      "South America     10199\n",
      "Antarctica            1\n",
      "Name: continent, dtype: int64\n",
      "number of values with <5 counts is 1\n",
      "=================================\n",
      "-999         314313\n",
      "London         9828\n",
      "New York       8737\n",
      "Bangalore      8264\n",
      "Mumbai         8035\n",
      "              ...  \n",
      "Reinosa           1\n",
      "Gosnells          1\n",
      "Reinsvoll         1\n",
      "Gosier            1\n",
      "Saltburn          1\n",
      "Name: city, Length: 26138, dtype: int64\n",
      "number of values with <5 counts is 17436\n",
      "=================================\n",
      "-999    352147\n",
      "CA       45270\n",
      "MA       26910\n",
      "NY       26658\n",
      "ON       19643\n",
      "         ...  \n",
      "321          1\n",
      "322          1\n",
      "327          1\n",
      "FER          1\n",
      "JRA          1\n",
      "Name: region, Length: 1084, dtype: int64\n",
      "number of values with <5 counts is 170\n",
      "=================================\n",
      "-999                 334574\n",
      "California            44904\n",
      "New York              26658\n",
      "Massachusetts         25090\n",
      "Ontario               19632\n",
      "                      ...  \n",
      "Changwat Buriram          1\n",
      "Madang Province           1\n",
      "Changwat Kalasin          1\n",
      "Changwat Lop Buri         1\n",
      "Raionul Calarasi          1\n",
      "Name: subdivision, Length: 2508, dtype: int64\n",
      "number of values with <5 counts is 653\n",
      "=================================\n",
      "-999     704467\n",
      "K2H        4390\n",
      "02138      2677\n",
      "10001      2287\n",
      "10245      2258\n",
      "          ...  \n",
      "41980         1\n",
      "4198          1\n",
      "41960         1\n",
      "4194          1\n",
      "x5003         1\n",
      "Name: postalCode, Length: 33174, dtype: int64\n",
      "number of values with <5 counts is 20194\n",
      "=================================\n",
      "b        336866\n",
      "m        249426\n",
      "hs       228176\n",
      "-999     165953\n",
      "a         51646\n",
      "p         43081\n",
      "jhs       30047\n",
      "other     21683\n",
      "el         4543\n",
      "p_se       4131\n",
      "none       3297\n",
      "p_oth      2886\n",
      "Name: LoE, dtype: int64\n",
      "number of values with <5 counts is 0\n",
      "=================================\n",
      "m       590462\n",
      "f       392971\n",
      "-999    152119\n",
      "o         6183\n",
      "Name: gender, dtype: int64\n",
      "number of values with <5 counts is 0\n",
      "=================================\n",
      "honor       626922\n",
      "audit       495024\n",
      "verified     14718\n",
      "-999          5071\n",
      "Name: mode, dtype: int64\n",
      "number of values with <5 counts is 0\n",
      "=================================\n",
      "gmail.com             675538\n",
      "hotmail.com           104199\n",
      "yahoo.com              80300\n",
      "outlook.com            16407\n",
      "qq.com                 10620\n",
      "                       ...  \n",
      "murdochdubai.ac.ae         1\n",
      "murday.co.uk               1\n",
      "murciaeduca.es             1\n",
      "muraterbezci.com           1\n",
      "004.dk                     1\n",
      "Name: email_domain, Length: 45430, dtype: int64\n",
      "number of values with <5 counts is 42507\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "for i in categorical:\n",
    "    counts = df[i].value_counts()\n",
    "    filtered = counts[counts <= 5]\n",
    "    print(counts)\n",
    "    print(\"number of values with <5 counts is %i\"%len(filtered))\n",
    "    print(\"=================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'course_id': number of values with <5 counts is 1, leave it there for checking completion rate\n",
    "\n",
    "* 'cc_by_ip': number of values with <5 counts is 11, leave it there. We could remove those records in surpression algorithm. It would be taking too much computation power and time consuming to generalize, and it may lose too much info if we blurring and delete. I will keep it there.\n",
    "\n",
    "\n",
    "* 'countryLabel': number of values with <5 counts is 16, leave it there. We could remove those records in surpression algorithm. It would be taking too much computation power and time consuming to generalize, and it may lose too much info if we blurring and delete. I will keep it there.\n",
    "\n",
    "\n",
    "* 'continent': number of values with <5 counts is 1, leave it there. We could remove those records in surpression algorithm. It would be taking too much computation power and time consuming to generalize, and it may lose too much info if we blurring and delete. I will keep it there.\n",
    "\n",
    "\n",
    "* 'city': number of values with <5 counts is 17436, which is large, maybe consider blurring this field would be better. \n",
    "\n",
    "* 'region': number of values with <5 counts is 170, which is okay, we could remove those records in surpression algorithm. It would be taking too much computation power and time consuming to generalize, and it may lose too much info if we blurring and delete. I will keep it there.\n",
    "\n",
    "* 'subdivision': number of values with <5 counts is 653, which is okay, we could remove those records in surpression algorithm. It would be taking too much computation power and time consuming to generalize, and it may lose too much info if we blurring and delete. I will keep it there.\n",
    "\n",
    "* 'postalCode': number of values with <5 counts is 20194, which is large, maybe consider blurring this field would be better. \n",
    "* 'LoE': number of values with <5 counts is 0, we could keep this variable there without doing anything as it already have a good level of anonmity and generalization in this column\n",
    "\n",
    "* 'gender': number of values with <5 counts is 0, we could keep this variable there without doing anything as it already have a good level of anonmity and generalization in this column\n",
    "\n",
    "* 'mode': number of values with <5 counts is 0, we could keep this variable there without doing anything as it already have a good level of anonmity and generalization in this column\n",
    "\n",
    "* 'email_domain': number of values with <5 counts is 42507, maybe consider blurring this field would be better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_blurring = ['city','postalCode', 'LoE', 'email_domain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all numerical columns, we could try to generalize it and divide them into sub categories and partitions, which will be written in details in **generalize** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'YoB':  partition and split into different year range based on a 10 year interval (50s, 60s, 70s etc.)\n",
    "* 'nforum_posts': partition and split into different bins according to quantile\n",
    "* 'nforum_votes': same as above\n",
    "* 'nforum_endorsed': same as above\n",
    "* 'nforum_threads': same as above\n",
    "* 'nforum_comments': same as above\n",
    "* 'nforum_pinned': same as above\n",
    "* 'nforum_events': same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split(df, partition, column):\n",
    "#     dfp = df[column][partition]\n",
    "#     if column in categorical:\n",
    "#         values = dfp.unique()\n",
    "#         lv = set(values[:len(values)//2])\n",
    "#         rv = set(values[len(values)//2:])\n",
    "#         return dfp.index[dfp.isin(lv)], dfp.index[dfp.isin(rv)]\n",
    "#     elif column in numerical:        \n",
    "#         median = dfp.median()\n",
    "#         dfl = dfp.index[dfp < median]\n",
    "#         dfr = dfp.index[dfp >= median]\n",
    "#         return (dfl, dfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Blurring and Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurring (column suppression, removing whole columns that don't fit for k-anonymity) \n",
    "def blurring(df, col):\n",
    "    result_df = df.drop(columns=[col])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalization (changing column values to be more general such as using an age range instead of a specific age)\n",
    "def generalize(df, col, partition = 4):\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    ## generalize YoB into Bins\n",
    "    if col == \"YoB\":\n",
    "        result_df['age'] = pd.cut(result_df.YoB, [-1000, 1950, 1960,1970,1980,1990,2000,2010,2020, max(result_df.YoB)+1], \n",
    "               labels = [\"50s-\", \"50s\", '60s','70s','80s','90s','00s','10s','20s+']).astype(str)\n",
    "    \n",
    "    ## if col is numerical other than YoB, generalize them into sub-bins by quantiles\n",
    "    elif col in numerical: \n",
    "        #result_df.sort_values(by =[col], inplace = True)\n",
    "        #result_df[str(col+\"_percentile\")] = pd.qcut(result_df[col], q = partition, labels = False, duplicates = \"raise\") \n",
    "        span = max(result_df[col]) - 0\n",
    "        interval = 1/partition\n",
    "        partition_lst = [i*interval*span for i in range(partition)]\n",
    "        label_lst = ['q'+str(i) for i in range(partition)]\n",
    "        pd_cut_full_lst, label_full_lst = [-1000], [\"q1-\"]\n",
    "        pd_cut_full_lst += partition_lst\n",
    "        label_full_lst += label_lst\n",
    "        pd_cut_full_lst.append(max(result_df[col])+1)\n",
    "        #print(pd_cut_full_lst)\n",
    "        #print(label_full_lst)\n",
    "        result_df[str(col+\"_percentile\")] = pd.cut(result_df[col], pd_cut_full_lst, labels = label_full_lst).astype(str)\n",
    "    \n",
    "    ## last step: remove original column\n",
    "    result_df = result_df.drop(columns=[col])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= blurring(df, \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          50s-\n",
       "1          50s-\n",
       "2          50s-\n",
       "3          50s-\n",
       "4           80s\n",
       "           ... \n",
       "1141730    50s-\n",
       "1141731     90s\n",
       "1141732    50s-\n",
       "1141733     80s\n",
       "1141734     90s\n",
       "Name: age, Length: 1141735, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deal with YoB\n",
    "df1 = generalize(df, \"YoB\")\n",
    "df1['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>registered</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>completed</th>\n",
       "      <th>ip</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>roles_isStaff</th>\n",
       "      <th>roles_isCCX</th>\n",
       "      <th>roles_isFinance</th>\n",
       "      <th>roles_isLibrary</th>\n",
       "      <th>roles_isSales</th>\n",
       "      <th>forumRoles_isAdmin</th>\n",
       "      <th>forumRoles_isCommunityTA</th>\n",
       "      <th>forumRoles_isModerator</th>\n",
       "      <th>forumRoles_isStudent</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1488411</td>\n",
       "      <td>KIRSTEN SUAREZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.108.107.58</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50s-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>7013084</td>\n",
       "      <td>CAREY FOSTER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>205.175.107.76</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50s-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4083257</td>\n",
       "      <td>CLAUDINE FARMER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.212.146.137</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50s-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4605571</td>\n",
       "      <td>SHEREE BONNER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>172.221.204.94</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50s-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1499820</td>\n",
       "      <td>MITCHELL VALDEZ</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>193.225.200.92</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id  user_id         username  registered  viewed  \\\n",
       "0  HarvardX/PH525.1x/1T2018  1488411   KIRSTEN SUAREZ        True   False   \n",
       "1  HarvardX/PH525.1x/1T2018  7013084     CAREY FOSTER        True    True   \n",
       "2  HarvardX/PH525.1x/1T2018  4083257  CLAUDINE FARMER        True    True   \n",
       "3  HarvardX/PH525.1x/1T2018  4605571    SHEREE BONNER        True    True   \n",
       "4  HarvardX/PH525.1x/1T2018  1499820  MITCHELL VALDEZ        True    True   \n",
       "\n",
       "  explored  certified  completed               ip cc_by_ip  ... roles_isStaff  \\\n",
       "0     -999      False      False    81.108.107.58       GB  ...        -999.0   \n",
       "1     True      False      False   205.175.107.76       US  ...        -999.0   \n",
       "2    False      False      False  103.212.146.137     -999  ...        -999.0   \n",
       "3    False      False      False   172.221.204.94       US  ...        -999.0   \n",
       "4     True      False      False   193.225.200.92       HU  ...        -999.0   \n",
       "\n",
       "  roles_isCCX roles_isFinance roles_isLibrary roles_isSales  \\\n",
       "0      -999.0          -999.0          -999.0        -999.0   \n",
       "1      -999.0          -999.0          -999.0        -999.0   \n",
       "2      -999.0          -999.0          -999.0        -999.0   \n",
       "3      -999.0          -999.0          -999.0        -999.0   \n",
       "4      -999.0          -999.0          -999.0        -999.0   \n",
       "\n",
       "  forumRoles_isAdmin forumRoles_isCommunityTA forumRoles_isModerator  \\\n",
       "0             -999.0                   -999.0                 -999.0   \n",
       "1             -999.0                   -999.0                 -999.0   \n",
       "2             -999.0                   -999.0                 -999.0   \n",
       "3             -999.0                   -999.0                 -999.0   \n",
       "4             -999.0                   -999.0                 -999.0   \n",
       "\n",
       "  forumRoles_isStudent   age  \n",
       "0                  1.0  50s-  \n",
       "1                  1.0  50s-  \n",
       "2                  1.0  50s-  \n",
       "3                  1.0  50s-  \n",
       "4                  1.0   80s  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1141735\n",
       "unique          5\n",
       "top           q1-\n",
       "freq      1102375\n",
       "Name: nforum_posts_percentile, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deal with nForum\n",
    "df1 = generalize(df, \"nforum_posts\")\n",
    "df1['nforum_posts_percentile'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30069\n",
      "                         completed\n",
      "course_id                         \n",
      "HarvardX/1368.1x/2T2016   0.033592\n",
      "HarvardX/1368.1x/3T2014   0.061265\n",
      "HarvardX/1368.2x/2T2015   0.064698\n",
      "HarvardX/1368.2x/2T2016   0.102389\n",
      "HarvardX/1368.3x/2T2015   0.081613\n",
      "...                            ...\n",
      "Harvardx/HLS2X/T12016     0.086794\n",
      "VJx/VJx/3T2014            0.080372\n",
      "VJx/VJx/3T2015            0.095238\n",
      "VJx/VJx_2/3T2016          0.045650\n",
      "VJx/VJx_S/3T2015          0.029367\n",
      "\n",
      "[279 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# test suppression on new df1\n",
    "len_remove, lst_remove = supression(df1, quasi_lists[:3], 5)\n",
    "print(len_remove)\n",
    "data_drop_3_age = data.drop(lst_remove, axis=0)\n",
    "rate_3_age = complete_rate(data_drop_3_age)\n",
    "print(rate_3_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver script repeatedly search with different generalization and blurring choices, to achieve 5-anonmity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_search(col_lst, df):\n",
    "    remove_dict = {}\n",
    "    total_completion_rate_dict = {}\n",
    "    for i in col_lst:\n",
    "        quasi_lists_copy = quasi_lists.copy()\n",
    "        if i in numerical:\n",
    "            temp_df = generalize(df, i)\n",
    "            # new quasi_lists after generalize\n",
    "            print(quasi_lists_copy)\n",
    "            quasi_lists_copy.remove(i)\n",
    "            if i == \"YoB\":\n",
    "                quasi_lists_copy.append(\"age\")\n",
    "            else:\n",
    "                quasi_lists_copy.append(str(i+\"_percentile\"))\n",
    "            len_remove, lst_remove = supression(temp_df, quasi_lists_copy, 5)\n",
    "            print(\"if generalize on \"+ i + \" we need to remove \"+ str(len_remove) + \" records.\")\n",
    "        elif i in categorical_blurring:\n",
    "            temp_df = blurring(df, i)\n",
    "            # new quasi_lists after blurring\n",
    "            quasi_lists_copy.remove(i)\n",
    "            len_remove, lst_remove = supression(temp_df, quasi_lists_copy, 5)\n",
    "            print(\"if blurring on \"+ i + \" we need to remove \"+ str(len_remove) + \" records.\")\n",
    "        data_drop= temp_df.drop(lst_remove, axis=0)\n",
    "        rate = complete_rate(data_drop)\n",
    "        total_rate = (data_drop[[\"completed\"]].sum()) / (data_drop[[\"completed\"]].count())\n",
    "        print(\"total completion rate is : %.4f\"%total_rate)\n",
    "        remove_dict[i] = len_remove\n",
    "        total_completion_rate_dict[i] = total_rate\n",
    "        print(\"===========================================\")\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'postalCode',\n",
       " 'LoE',\n",
       " 'email_domain',\n",
       " 'YoB',\n",
       " 'nforum_posts',\n",
       " 'nforum_votes',\n",
       " 'nforum_endorsed',\n",
       " 'nforum_threads',\n",
       " 'nforum_comments',\n",
       " 'nforum_pinned',\n",
       " 'nforum_events']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_lst = categorical_blurring + numerical\n",
    "search_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if blurring on city we need to remove 1028395 records.\n",
      "total completion rate is : 0.0013\n",
      "===========================================\n",
      "if blurring on postalCode we need to remove 1024271 records.\n",
      "total completion rate is : 0.0013\n",
      "===========================================\n",
      "if blurring on LoE we need to remove 994799 records.\n",
      "total completion rate is : 0.0014\n",
      "===========================================\n",
      "if blurring on email_domain we need to remove 973672 records.\n",
      "total completion rate is : 0.0016\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on YoB we need to remove 964866 records.\n",
      "total completion rate is : 0.0018\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_posts we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_votes we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_endorsed we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_threads we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_comments we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_pinned we need to remove 1033540 records.\n",
      "total completion rate is : 0.0012\n",
      "===========================================\n",
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on nforum_events we need to remove 1023587 records.\n",
      "total completion rate is : 0.0013\n",
      "===========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>registered</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>completed</th>\n",
       "      <th>ip</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>roles_isStaff</th>\n",
       "      <th>roles_isCCX</th>\n",
       "      <th>roles_isFinance</th>\n",
       "      <th>roles_isLibrary</th>\n",
       "      <th>roles_isSales</th>\n",
       "      <th>forumRoles_isAdmin</th>\n",
       "      <th>forumRoles_isCommunityTA</th>\n",
       "      <th>forumRoles_isModerator</th>\n",
       "      <th>forumRoles_isStudent</th>\n",
       "      <th>nforum_events_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1488411</td>\n",
       "      <td>KIRSTEN SUAREZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.108.107.58</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>7013084</td>\n",
       "      <td>CAREY FOSTER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>205.175.107.76</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4083257</td>\n",
       "      <td>CLAUDINE FARMER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.212.146.137</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4605571</td>\n",
       "      <td>SHEREE BONNER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>172.221.204.94</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1499820</td>\n",
       "      <td>MITCHELL VALDEZ</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>193.225.200.92</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141730</th>\n",
       "      <td>HarvardX/PH525.5x/2T2018</td>\n",
       "      <td>1388822</td>\n",
       "      <td>WILLIE HOGAN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141731</th>\n",
       "      <td>HarvardX/PH525.5x/2T2018</td>\n",
       "      <td>9210079</td>\n",
       "      <td>ESTELA WRIGHT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>59.180.173.247</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141732</th>\n",
       "      <td>HarvardX/PH525.5x/2T2018</td>\n",
       "      <td>6212000</td>\n",
       "      <td>NONA HALEY</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>124.17.34.78</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141733</th>\n",
       "      <td>HarvardX/PH525.5x/2T2018</td>\n",
       "      <td>945808</td>\n",
       "      <td>JULIO SANDOVAL</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>191.177.186.50</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141734</th>\n",
       "      <td>HarvardX/PH525.5x/2T2018</td>\n",
       "      <td>5224943</td>\n",
       "      <td>MELVIN HUFFMAN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14.142.16.34</td>\n",
       "      <td>IN</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>q1-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1141735 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course_id  user_id         username  registered  \\\n",
       "0        HarvardX/PH525.1x/1T2018  1488411   KIRSTEN SUAREZ        True   \n",
       "1        HarvardX/PH525.1x/1T2018  7013084     CAREY FOSTER        True   \n",
       "2        HarvardX/PH525.1x/1T2018  4083257  CLAUDINE FARMER        True   \n",
       "3        HarvardX/PH525.1x/1T2018  4605571    SHEREE BONNER        True   \n",
       "4        HarvardX/PH525.1x/1T2018  1499820  MITCHELL VALDEZ        True   \n",
       "...                           ...      ...              ...         ...   \n",
       "1141730  HarvardX/PH525.5x/2T2018  1388822     WILLIE HOGAN        True   \n",
       "1141731  HarvardX/PH525.5x/2T2018  9210079    ESTELA WRIGHT        True   \n",
       "1141732  HarvardX/PH525.5x/2T2018  6212000       NONA HALEY        True   \n",
       "1141733  HarvardX/PH525.5x/2T2018   945808   JULIO SANDOVAL        True   \n",
       "1141734  HarvardX/PH525.5x/2T2018  5224943   MELVIN HUFFMAN        True   \n",
       "\n",
       "         viewed explored  certified  completed               ip cc_by_ip  ...  \\\n",
       "0         False     -999      False      False    81.108.107.58       GB  ...   \n",
       "1          True     True      False      False   205.175.107.76       US  ...   \n",
       "2          True    False      False      False  103.212.146.137     -999  ...   \n",
       "3          True    False      False      False   172.221.204.94       US  ...   \n",
       "4          True     True      False      False   193.225.200.92       HU  ...   \n",
       "...         ...      ...        ...        ...              ...      ...  ...   \n",
       "1141730   False     -999      False      False             -999     -999  ...   \n",
       "1141731   False     -999      False      False   59.180.173.247       IN  ...   \n",
       "1141732   False     -999      False      False     124.17.34.78       CN  ...   \n",
       "1141733   False     -999      False      False   191.177.186.50       BR  ...   \n",
       "1141734   False     -999      False      False     14.142.16.34       IN  ...   \n",
       "\n",
       "        roles_isStaff roles_isCCX roles_isFinance roles_isLibrary  \\\n",
       "0              -999.0      -999.0          -999.0          -999.0   \n",
       "1              -999.0      -999.0          -999.0          -999.0   \n",
       "2              -999.0      -999.0          -999.0          -999.0   \n",
       "3              -999.0      -999.0          -999.0          -999.0   \n",
       "4              -999.0      -999.0          -999.0          -999.0   \n",
       "...               ...         ...             ...             ...   \n",
       "1141730        -999.0      -999.0          -999.0          -999.0   \n",
       "1141731        -999.0      -999.0          -999.0          -999.0   \n",
       "1141732        -999.0      -999.0          -999.0          -999.0   \n",
       "1141733        -999.0      -999.0          -999.0          -999.0   \n",
       "1141734        -999.0      -999.0          -999.0          -999.0   \n",
       "\n",
       "        roles_isSales forumRoles_isAdmin forumRoles_isCommunityTA  \\\n",
       "0              -999.0             -999.0                   -999.0   \n",
       "1              -999.0             -999.0                   -999.0   \n",
       "2              -999.0             -999.0                   -999.0   \n",
       "3              -999.0             -999.0                   -999.0   \n",
       "4              -999.0             -999.0                   -999.0   \n",
       "...               ...                ...                      ...   \n",
       "1141730        -999.0             -999.0                   -999.0   \n",
       "1141731        -999.0             -999.0                   -999.0   \n",
       "1141732        -999.0             -999.0                   -999.0   \n",
       "1141733        -999.0             -999.0                   -999.0   \n",
       "1141734        -999.0             -999.0                   -999.0   \n",
       "\n",
       "        forumRoles_isModerator forumRoles_isStudent nforum_events_percentile  \n",
       "0                       -999.0                  1.0                      q1-  \n",
       "1                       -999.0                  1.0                      q1-  \n",
       "2                       -999.0                  1.0                      q1-  \n",
       "3                       -999.0                  1.0                      q1-  \n",
       "4                       -999.0                  1.0                      q1-  \n",
       "...                        ...                  ...                      ...  \n",
       "1141730                 -999.0                  1.0                      q1-  \n",
       "1141731                 -999.0                  1.0                      q1-  \n",
       "1141732                 -999.0                  1.0                      q1-  \n",
       "1141733                 -999.0                  1.0                      q1-  \n",
       "1141734                 -999.0                  1.0                      q1-  \n",
       "\n",
       "[1141735 rows x 92 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_search(search_lst, df)\n",
    "#naive_search([\"'YoB', \"nforum_posts\"], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above search we could see that, if we only search for manipulating minimal number of columns (which is 1 in this case, as we didn't do an exhaustive grid search on all permutations of columns for generalization or blurring), the results are shown above.\n",
    "\n",
    "If we want highest total completion rate, we should **generalize on YoB**, which leads to 0.0018 completion rate when we suppress and get 5-anonymity \n",
    "\n",
    "If we want to remove least records, we should also choose to **generalize on YoB**, which only needs to remove 964866 records for suppression to get 5-anonymity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary: **\n",
    "\n",
    "Based on the approach we adopted, we first learned from the data generated in Step 3 that different generalization and blurring choices result in output that varies. This makes subjective choices necessary in the process of de-identification both in terms of selecting the statistical techniques for de-identification and determining the generated data set that best represents the original dataset. \n",
    "\n",
    "Second, we realized from this practice that regardless of the techniques we use, the process of de-identification will inevitably change the structure and nature of the original dataset and make the final de-identified dataset less accurate. For instance, after generalization on YoB for realizing 5-anonymity, the total completion rate is 0.18%, which is wildly different from what we would have gotten from the original dataset, which is 4%. Admittedly, this statistics (and others generated from our de-identified datasets) could have been improved if we did an exhaustive grid search on all permutations of columns for generalization or blurring. Indeed, this recognized limitation leads to the last lesson we learned from the Step 3 exercise: Generating high quality de-identified dataset that is meaningful and useful for future research is a laborious but rewarding task that requires researchers to be wholeheartedly devoted to advancing their technical skills and fulfilling their ethical obligations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - I-Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_variables = [\"completed\" , 'grade', 'cert_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', 'mode', 'email_domain']\n",
      "if generalize on YoB we need to remove 964866 records.\n",
      "total completion rate is : 0.0018\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "df_new_after_step_3 = naive_search([\"YoB\"], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive variable name: completed\n",
      "False    1113593\n",
      "True       28142\n",
      "Name: completed, dtype: int64\n",
      "=============================================\n",
      "sensitive variable name: grade\n",
      " 0.00      727322\n",
      "-999.00    321067\n",
      " 0.01        6491\n",
      " 0.03        5933\n",
      " 0.02        4756\n",
      "            ...  \n",
      " 1.05           3\n",
      " 1.19           1\n",
      " 1.16           1\n",
      " 1.11           1\n",
      " 1.15           1\n",
      "Name: grade, Length: 114, dtype: int64\n",
      "=============================================\n",
      "sensitive variable name: cert_status\n",
      "-999                614558\n",
      "notpassing          487232\n",
      "downloadable         22675\n",
      "audit_notpassing     16582\n",
      "audit_passing          447\n",
      "unverified             220\n",
      "unavailable             20\n",
      "error                    1\n",
      "Name: cert_status, dtype: int64\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "for var in sensitive_variables:\n",
    "    i_diversity = df_new_after_step_3[var].value_counts()\n",
    "    print(\"sensitive variable name: \"+var)\n",
    "    print(i_diversity)\n",
    "    print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_quasi_lists =  ['course_id', 'cc_by_ip', 'countryLabel', 'continent', 'city', 'region',\n",
    "              'subdivision', 'postalCode', 'LoE', 'age', 'gender', 'nforum_posts', 'nforum_votes', \n",
    "              'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events', \n",
    "              'mode', 'email_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take l-diveristy for each group divided by new quasi list\n",
    "\n",
    "grouped = df_new_after_step_3.groupby(by=new_quasi_lists)\n",
    "\n",
    "l_diversity =  {\"completed\":{}, 'grade':{}, 'cert_status':{}}\n",
    "\n",
    "for name, group in grouped:\n",
    "    for var in sensitive_variables:\n",
    "\n",
    "        l_div = group[var].nunique()\n",
    "        if l_div in l_diversity[var].keys():\n",
    "            l_diversity[var][l_div] += 1\n",
    "        else:\n",
    "            l_diversity[var][l_div] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completed': {1: 908040, 2: 893},\n",
       " 'grade': {1: 898097,\n",
       "  2: 9887,\n",
       "  5: 55,\n",
       "  3: 728,\n",
       "  4: 128,\n",
       "  6: 23,\n",
       "  8: 3,\n",
       "  9: 5,\n",
       "  14: 1,\n",
       "  7: 2,\n",
       "  11: 2,\n",
       "  10: 2},\n",
       " 'cert_status': {1: 901483, 2: 7364, 3: 86}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only look at minimal *l-diversity* in all block for three variables:\n",
    "\n",
    "**all of them acheived only 1-diversity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[min(l_diversity[var].keys()) for var in sensitive_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For testing, we would test our blurring and generalizing algorithm to make sure the code we write to deal with the dataframe will produce the right answer we expected when it ran to completion.\n",
    "We won't do exhaustive testing or unit test for every single line we wrote here like what traditional software development do. Below is a demo for testing.\n",
    "\n",
    "> If we have more time to improve, testing should cover different aspects, algorithms and possible columns on a subset of dataframe, to make sure every mechanism works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>registered</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>completed</th>\n",
       "      <th>ip</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>roles_isInstructor</th>\n",
       "      <th>roles_isStaff</th>\n",
       "      <th>roles_isCCX</th>\n",
       "      <th>roles_isFinance</th>\n",
       "      <th>roles_isLibrary</th>\n",
       "      <th>roles_isSales</th>\n",
       "      <th>forumRoles_isAdmin</th>\n",
       "      <th>forumRoles_isCommunityTA</th>\n",
       "      <th>forumRoles_isModerator</th>\n",
       "      <th>forumRoles_isStudent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1488411</td>\n",
       "      <td>KIRSTEN SUAREZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.108.107.58</td>\n",
       "      <td>GB</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>7013084</td>\n",
       "      <td>CAREY FOSTER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>205.175.107.76</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4083257</td>\n",
       "      <td>CLAUDINE FARMER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.212.146.137</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>4605571</td>\n",
       "      <td>SHEREE BONNER</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>172.221.204.94</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>1499820</td>\n",
       "      <td>MITCHELL VALDEZ</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>193.225.200.92</td>\n",
       "      <td>HU</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>3872821</td>\n",
       "      <td>CLYDE FINCH</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>177.18.230.216</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>7560679</td>\n",
       "      <td>MITZI AVERY</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>73.153.215.76</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>18306</td>\n",
       "      <td>IRIS MARQUEZ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.84.185.183</td>\n",
       "      <td>GR</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>6530939</td>\n",
       "      <td>LYNETTE GRAHAM</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>129.21.116.121</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>8874860</td>\n",
       "      <td>KATE ROWLAND</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>77.245.2.66</td>\n",
       "      <td>JO</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id  user_id         username  registered  viewed  \\\n",
       "0  HarvardX/PH525.1x/1T2018  1488411   KIRSTEN SUAREZ        True   False   \n",
       "1  HarvardX/PH525.1x/1T2018  7013084     CAREY FOSTER        True    True   \n",
       "2  HarvardX/PH525.1x/1T2018  4083257  CLAUDINE FARMER        True    True   \n",
       "3  HarvardX/PH525.1x/1T2018  4605571    SHEREE BONNER        True    True   \n",
       "4  HarvardX/PH525.1x/1T2018  1499820  MITCHELL VALDEZ        True    True   \n",
       "5  HarvardX/PH525.1x/1T2018  3872821      CLYDE FINCH        True    True   \n",
       "6  HarvardX/PH525.1x/1T2018  7560679      MITZI AVERY        True    True   \n",
       "7  HarvardX/PH525.1x/1T2018    18306     IRIS MARQUEZ        True   False   \n",
       "8  HarvardX/PH525.1x/1T2018  6530939   LYNETTE GRAHAM        True   False   \n",
       "9  HarvardX/PH525.1x/1T2018  8874860     KATE ROWLAND        True   False   \n",
       "\n",
       "  explored  certified  completed               ip cc_by_ip  ...  \\\n",
       "0     -999      False      False    81.108.107.58       GB  ...   \n",
       "1     True      False      False   205.175.107.76       US  ...   \n",
       "2    False      False      False  103.212.146.137     -999  ...   \n",
       "3    False      False      False   172.221.204.94       US  ...   \n",
       "4     True      False      False   193.225.200.92       HU  ...   \n",
       "5    False      False      False   177.18.230.216       BR  ...   \n",
       "6     True      False      False    73.153.215.76       US  ...   \n",
       "7     -999      False      False     2.84.185.183       GR  ...   \n",
       "8     -999      False      False   129.21.116.121       US  ...   \n",
       "9     -999      False      False      77.245.2.66       JO  ...   \n",
       "\n",
       "  roles_isInstructor roles_isStaff roles_isCCX roles_isFinance  \\\n",
       "0             -999.0        -999.0      -999.0          -999.0   \n",
       "1             -999.0        -999.0      -999.0          -999.0   \n",
       "2             -999.0        -999.0      -999.0          -999.0   \n",
       "3             -999.0        -999.0      -999.0          -999.0   \n",
       "4             -999.0        -999.0      -999.0          -999.0   \n",
       "5             -999.0        -999.0      -999.0          -999.0   \n",
       "6             -999.0        -999.0      -999.0          -999.0   \n",
       "7             -999.0        -999.0      -999.0          -999.0   \n",
       "8             -999.0        -999.0      -999.0          -999.0   \n",
       "9             -999.0        -999.0      -999.0          -999.0   \n",
       "\n",
       "  roles_isLibrary roles_isSales forumRoles_isAdmin forumRoles_isCommunityTA  \\\n",
       "0          -999.0        -999.0             -999.0                   -999.0   \n",
       "1          -999.0        -999.0             -999.0                   -999.0   \n",
       "2          -999.0        -999.0             -999.0                   -999.0   \n",
       "3          -999.0        -999.0             -999.0                   -999.0   \n",
       "4          -999.0        -999.0             -999.0                   -999.0   \n",
       "5          -999.0        -999.0             -999.0                   -999.0   \n",
       "6          -999.0        -999.0             -999.0                   -999.0   \n",
       "7          -999.0        -999.0             -999.0                   -999.0   \n",
       "8          -999.0        -999.0             -999.0                   -999.0   \n",
       "9          -999.0        -999.0             -999.0                   -999.0   \n",
       "\n",
       "  forumRoles_isModerator forumRoles_isStudent  \n",
       "0                 -999.0                  1.0  \n",
       "1                 -999.0                  1.0  \n",
       "2                 -999.0                  1.0  \n",
       "3                 -999.0                  1.0  \n",
       "4                 -999.0                  1.0  \n",
       "5                 -999.0                  1.0  \n",
       "6                 -999.0                  1.0  \n",
       "7                 -999.0                  1.0  \n",
       "8                 -999.0                  1.0  \n",
       "9                 -999.0                  1.0  \n",
       "\n",
       "[10 rows x 92 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sample sub dataframe for testing\n",
    "test_df = df[:10]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = supression(test_df, quasi_lists[:3], 3)\n",
    "# by manually grouping the dataset and check the result\n",
    "assert test1[0] == 6\n",
    "assert test1[1] == [2, 5, 0, 7, 4, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = supression(test_df, quasi_lists[6:10], 4)\n",
    "# by manually grouping the dataset and check the result\n",
    "assert test2[0] == 6\n",
    "assert test2[1] == [7, 4, 0, 8, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = synthetic_records(test_df, quasi_lists[6:10], 4)\n",
    "# by manually grouping the dataset and check the result\n",
    "assert test3 == 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = synthetic_records(test_df, quasi_lists[:3], 5)\n",
    "# by manually grouping the dataset and check the result\n",
    "assert test4 == 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_blurring(test_df, col):\n",
    "    result = blurring(test_df, col)\n",
    "    expected = test_df.drop(col, 1)\n",
    "    assert result.equals(expected)\n",
    "\n",
    "test_blurring(test_df, \"registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generalize_nforum(full_df, test_df, col):\n",
    "    result = generalize(full_df, col)\n",
    "    result = result[:10]\n",
    "    expected = test_df.copy()\n",
    "    expected[str(col+\"_percentile\")] = \"q1-\"\n",
    "    expected = expected.drop(columns=[col])\n",
    "    assert result.equals(expected)\n",
    "\n",
    "test_generalize_nforum(df, test_df, \"nforum_posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Our algorithm work well and passed testing by not throwing any assertion errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "    \n",
    "We defined “completed” (indicated that the user completed the course by achieving a final grade above the overall passing threshold for the course), “grade” (Final grade earned in the course, on a scale of 0 to 1), and “cert_status” (certification status, specified as ‘downloadable’, ‘notpassing’, ‘unavailable’, ‘audit_notpassing’, ‘audit_passing’ or ‘error’) as sensitive attributes. We made this decision based on the FERPA in which statistics related to student grades are protected.  Due to the special features of online learning platforms such as edX, we considered both a user’s completion status and certification status as sensitive information in addition to his/her grades. We proceeded our analysis with a dataset that generalizes on YoB because, based on the analysis from Step 3, this dataset has the total completion rate that is most close to the baseline rate and includes the most number of tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive analysis of the count of the values of **“completed”** reveals that this sensitive attribute is extremely vulnerable to the homogeneity attack because it only contains two values (‘True’ or ‘False’). In this case, for each q*-block that includes 5 tuples whose values for all the quasi-identifiers are identical, it is very likely that they have the same value for the attribute “completed” due to its lack of diversity. This means that knowing a person belonging to a certain q*-block without identifying exactly which record in this q*-block represents that person is sufficient for an adversary to obtain information on his/her completion of the course. Further analysis on the diversity of each q*-block of the dataset indicates that 908040 of the total blocks of tuples have an l-diversity of 1, putting an individual’s information in danger of being leaked.The rest q*-blocks have an l-diversity of 2, protecting an individual from homogeneity attack. Achieving a higher level of l-diversity for this attribute would mean to manipulate the data so that a give q*-block contains two values and their frequencies of occurrence are roughly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive analysis of the count of the values of **“grade”** reveals that this sensitive attribute is moderately vulnerable to the homogeneity attack and background knowledge because 1) the distribution of the grades is heavily left-skewed and 2) a person’s grade is highly related to their prior academic performance, information that is likely to be obtained by an adversary. Firstly, for each q*-block that includes 5 tuples whose values for all the quasi-identifiers are identical, it is very likely that they all have the most frequent grade (i.e., ‘0.00’) or grades that are less frequent but the amounts of occurrences are still substantial (e.g., ‘0.01’, ‘0.02’, ‘0.03’). This means that knowing a person belonging to a certain q*-block without identifying exactly which record in this q*-block represents that person is sufficient for an adversary to obtain information on his/her grade. Further analysis on the diversity of each q*-block of the dataset indicates that 898097 of the total blocks of tuples have an l-diversity of 1, putting an individual’s information in danger of being leaked.The rest q*-blocks have an l-diversity of 2 or more, protecting an individual from homogeneity attack but not necessarily protecting him/her from background knowledge. For instance, if a q*-block with 5 tuples includes only one tuple that has a grade of 0, with all the other tuples having a grade of 1, this would be a 2-diversity q*-block that is supposed to be sufficient to protect an individual's information. However, if an adversary who knows a certain person belonging to this given q*-block and manages to glean information from external datasets indicating that this person has poor school performance, it is reasonable for the adversary to conclude that this person’s grade for a given course is 0. Achieving a higher level of l-diversity for this attribute would thus mean to manipulate the data so that a give q*-block contains more than two values of the attribute so there is a reasonable range of grades and their frequencies of occurrence are roughly balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive analysis of the count of the values of **“cert_status”** reveals that this sensitive attribute is moderately vulnerable to the homogeneity attack and background knowledge because 1) the distribution of the status is heavily left-skewed and 2) a person’s audit/enrollment status is to some extent related to their professions, information that is likely to be obtained by an adversary. Firstly, for each q*-block that includes 5 tuples whose values for all the quasi-identifiers are identical, it is very likely that they all have the most frequent status (i.e., ‘not passing’) or status that is less frequent but the amounts of occurrences are still substantial (e.g., ‘downloadable’, ‘audit_notpassing’). This means that knowing a person belonging to a certain q*-block without identifying exactly which record in this q*-block represents that person is sufficient for an adversary to obtain information on his/her certification status. Further analysis on the diversity of each q*-block of the dataset indicates that 901483 of the total blocks of tuples have an l-diversity of 1, putting an individual’s information in danger of being leaked.The rest q*-blocks have an l-diversity of 2 or more, protecting an individual from homogeneity attack but not necessarily protecting him/her from background knowledge. For instance, if a q*-block with 5 tuples includes only one tuple that has a status ‘audit_notpassing’, with all the other tuples having ‘passing’,  this would be a 2-diversity q*-block that is supposed to be sufficient to protect an individual's information. However, if an adversary who knows a certain person belonging to this given q*-block and manages to glean information from external datasets indicating that this person has a busy work/study schedule, it is reasonable for the adversary to conclude that this person is very likely to audit the class and since there is only one value for the option audit, the adversary has enough confidence to conclude that this person is not passing. Achieving a higher level of l-diversity for this attribute would thus mean to manipulate the data so that a give q*-block contains at least two values for both the audit and enrollee options (i.e., an l-diversity of at least 4) and their frequencies of occurrence are roughly balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
